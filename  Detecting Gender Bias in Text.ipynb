{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "54530de4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\ASUS\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "import numpy as np\n",
    "import nltk\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "nltk.download('stopwords')\n",
    "from gensim.utils import simple_preprocess\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "c031b48d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# load txt file into dataframe\n",
    "df = pd.read_csv('generalized_swaps.txt', sep='\\t', header=None, names=['col1', 'col2'])\n",
    "# print first 5 rows of dataframe\n",
    "sentence1 = [simple_preprocess(str(sentence)) for sentence in df['col1']]\n",
    "sentence2 = [simple_preprocess(str(sentence)) for sentence in df['col2']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9649896a",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('en_core_web_sm')\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "def preprocess(text):\n",
    "    new_text = []\n",
    "    docs = nlp(text)\n",
    "    words = nltk.word_tokenize(text)\n",
    "    tokenizer = RegexpTokenizer(r'\\w+')\n",
    "    for token in docs:\n",
    "        if not token.is_punct:\n",
    "            txt = tokenizer.tokenize(token.text)\n",
    "            filtered_word = [word for word in txt if word.lower() not in stop_words]\n",
    "            new_text.extend(filtered_word)\n",
    "    return ' '.join(new_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "39b82090",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cb02be09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from nltk import word_tokenize, sent_tokenize\n",
    "# sentence = [word_tokenize(word) for word in sent_tokenize(sentence1)]\n",
    "# sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "c1b34153",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim.downloader as api\n",
    "sentences = sentence1 + sentence2\n",
    "model = api.load('word2vec-google-news-300')\n",
    "# model = Word2Vec(sentences, min_count=1, vector_size=100, workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "f654b9f6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"Key 'airwoman' not present\"",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[115], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m word_embed1 \u001b[38;5;241m=\u001b[39m [model[word] \u001b[38;5;28;01mfor\u001b[39;00m word \u001b[38;5;129;01min\u001b[39;00m sentence1]\n\u001b[0;32m      2\u001b[0m word_embed2 \u001b[38;5;241m=\u001b[39m [model[word] \u001b[38;5;28;01mfor\u001b[39;00m word \u001b[38;5;129;01min\u001b[39;00m sentence2]\n",
      "Cell \u001b[1;32mIn[115], line 1\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[1;32m----> 1\u001b[0m word_embed1 \u001b[38;5;241m=\u001b[39m [\u001b[43mmodel\u001b[49m\u001b[43m[\u001b[49m\u001b[43mword\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m word \u001b[38;5;129;01min\u001b[39;00m sentence1]\n\u001b[0;32m      2\u001b[0m word_embed2 \u001b[38;5;241m=\u001b[39m [model[word] \u001b[38;5;28;01mfor\u001b[39;00m word \u001b[38;5;129;01min\u001b[39;00m sentence2]\n",
      "File \u001b[1;32m~\\miniconda3\\lib\\site-packages\\gensim\\models\\keyedvectors.py:405\u001b[0m, in \u001b[0;36mKeyedVectors.__getitem__\u001b[1;34m(self, key_or_keys)\u001b[0m\n\u001b[0;32m    402\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key_or_keys, _KEY_TYPES):\n\u001b[0;32m    403\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_vector(key_or_keys)\n\u001b[1;32m--> 405\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m vstack([\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_vector(key) \u001b[38;5;28;01mfor\u001b[39;00m key \u001b[38;5;129;01min\u001b[39;00m key_or_keys])\n",
      "File \u001b[1;32m~\\miniconda3\\lib\\site-packages\\gensim\\models\\keyedvectors.py:405\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    402\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key_or_keys, _KEY_TYPES):\n\u001b[0;32m    403\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_vector(key_or_keys)\n\u001b[1;32m--> 405\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m vstack([\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_vector\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m key \u001b[38;5;129;01min\u001b[39;00m key_or_keys])\n",
      "File \u001b[1;32m~\\miniconda3\\lib\\site-packages\\gensim\\models\\keyedvectors.py:446\u001b[0m, in \u001b[0;36mKeyedVectors.get_vector\u001b[1;34m(self, key, norm)\u001b[0m\n\u001b[0;32m    422\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_vector\u001b[39m(\u001b[38;5;28mself\u001b[39m, key, norm\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[0;32m    423\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Get the key's vector, as a 1D numpy array.\u001b[39;00m\n\u001b[0;32m    424\u001b[0m \n\u001b[0;32m    425\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    444\u001b[0m \n\u001b[0;32m    445\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 446\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_index\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    447\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m norm:\n\u001b[0;32m    448\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfill_norms()\n",
      "File \u001b[1;32m~\\miniconda3\\lib\\site-packages\\gensim\\models\\keyedvectors.py:420\u001b[0m, in \u001b[0;36mKeyedVectors.get_index\u001b[1;34m(self, key, default)\u001b[0m\n\u001b[0;32m    418\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m default\n\u001b[0;32m    419\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 420\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mKey \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m not present\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mKeyError\u001b[0m: \"Key 'airwoman' not present\""
     ]
    }
   ],
   "source": [
    "word_embed1 = [model[word] for word in sentence1]\n",
    "word_embed2 = [model[word] for word in sentence2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b60f2ed9",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_col1 = np.mean(word_embed1, axis=0)\n",
    "mean_col2 = np.mean(word_embed2, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3785f91",
   "metadata": {},
   "outputs": [],
   "source": [
    "gender_direction = mean_col1 - mean_col2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "226e08fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "gender_direction /= np.linalg.norm(gender_direction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff19f445",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_embed_gender = {}\n",
    "for word in model.key_to_index:\n",
    "    embedding = model[word]\n",
    "    dot_product = np.dot(embedding.reshape(1,-1), gender_direction.T)\n",
    "    word_embed_gender[word] = dot_product[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "62533939",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "def analogy(word_a, word_b, word_c, model):\n",
    "    embed_a = model[word_a]\n",
    "    embed_b = model[word_b]\n",
    "    embed_c = model[word_c]\n",
    "    \n",
    "    vec_d = embed_b - embed_a\n",
    "    closest_word, closest_distance = None, float('inf')\n",
    "    for word in model.key_to_index:\n",
    "        if word in[word_a, word_b, word_c]:\n",
    "            continue\n",
    "        embedding = model[word].reshape(1,-1)\n",
    "        analogy_vector = (embed_c - vec_d).reshape(1,-1)\n",
    "        distance = cosine_similarity(embedding, analogy_vector)\n",
    "        \n",
    "        if distance < closest_distance:\n",
    "            closest_word = word\n",
    "            closest_distance = distance\n",
    "    return closest_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4388ebcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_a = 'man'\n",
    "word_b = 'king'\n",
    "word_c = 'woman'\n",
    "\n",
    "closest_word = analogy(word_a, word_b, word_c, model)\n",
    "print(f\"{word_a} is to {word_b} as {word_c} is to {closest_word}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd071892",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "972c9c2f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
